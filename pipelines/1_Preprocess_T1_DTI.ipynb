{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Sets directories:**\n",
    "   - **anapyze_dir:** Directory where the anapyze_directory is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T08:38:33.107451900Z",
     "start_time": "2023-10-13T08:38:33.100451800Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os,sys\n",
    "import shutil\n",
    "import gzip\n",
    "import nibabel as nib\n",
    "from os.path import join, exists, isdir, basename\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "anapyze_dir = r'C:\\Users\\jesus\\Work\\repos\\anapyze' \n",
    "anapyze_rsc = join(anapyze_dir,'resources')\n",
    "sys.path.insert(0,anapyze_dir)\n",
    "from spm import SPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Set directories:**\n",
    "   - **Patient Data Directory (dir_patients):** This points to the directory where patient data is stored. *Note that this script expects that you have run the 0_Reorder_Data.py first*\n",
    "\n",
    "**Set SPM:**\n",
    "  \n",
    "   - **SPM PATH:** Path for your installation of the Statistical Parametric Mapping (SPM) software \n",
    "\n",
    "**Template Images:**\n",
    "   - **TPM (Tissue Probability Maps) Image (tpm):** This is set to the path where the TPM.nii file resides within the SPM software directory. **Check that this is correct**. \n",
    "\n",
    "   - **CAT12 Gray Scale Template Volume (template_volumes):** This is set to the path in the SPM directory where the CAT12 toolbox's template volumes are stored. **Check that this is correct**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-13T08:47:22.515346400Z",
     "start_time": "2023-10-13T08:47:22.507347100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put your data directory here\n",
    "dir_patients = r'D:\\IBIS_DATA\\Prueba'\n",
    "\n",
    "# Standalone SPM Paths\n",
    "spm_path = r'C:\\Users\\jesus\\Work\\software\\spm12'\n",
    "#mcr_path = '/home/jsilva/software/Matlab_MCR/v93' \n",
    "\n",
    "# Change your templates here if necessary \\toolbox\\cat12\\templates_MNI152NLin2009cAsym\n",
    "tpm = join(spm_path, 'tpm','TPM.nii')\n",
    "template_volumes = join(spm_path, r'toolbox\\cat12\\templates_MNI152NLin2009cAsym','Template_0_GS.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This prepares a processing script that will process the collected T1 image files using SPM's CAT12 toolbox.\n",
    "\n",
    "A MATLAB script named 'cat_12.m' is created that is recommended to be run separately in MATLAB. Alternatively you can run it here stating run=False in the *spm_proc.cat12seg_imgs* line, but you will not take advantage of the multi-threading capabilities of cat12. It is fine for a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-13T08:47:24.003350100Z",
     "start_time": "2023-10-13T08:47:23.925284800Z"
    }
   },
   "outputs": [],
   "source": [
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "#This will create a cat_12.m file that must be run on MATLAB separately\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    check_cat_processing = [join(dir_subj, 'cat12', 'report', 'catreport_t1.pdf'),\n",
    "                            join(dir_subj, 'cat12', 'mri', 'mwp1t1.nii'),\n",
    "                            join(dir_subj, 'cat12', 'mri', 'mwp2t1.nii'),\n",
    "                            join(dir_subj, 'cat12', 'mri', 'mwp3t1.nii'),\n",
    "                            join(dir_subj, 'cat12', 'mri', 'p0t1.nii'),\n",
    "                            join(dir_subj, 'cat12', 'mri', 'wmt1.nii')]\n",
    "\n",
    "    if all(exists(j) for j in check_cat_processing):\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        t1_image = False\n",
    "        \n",
    "        files_ = os.listdir(dir_subj)\n",
    "    \n",
    "        for file_ in files_:\n",
    "    \n",
    "            if file_[0:2] == 'IN':\n",
    "                if file_[-3:] == 'nii':\n",
    "                    if 'T1' in file_:\n",
    "                        t1_image = join(dir_subj, file_)\n",
    "                        \n",
    "        if t1_image:\n",
    "            \n",
    "            cat12_dir = join(dir_subj, 'cat12')\n",
    "            \n",
    "            if not exists(cat12_dir):\n",
    "                os.makedirs(cat12_dir)\n",
    "    \n",
    "            rm_in = join(cat12_dir,'t1.nii')\n",
    "            shutil.copy(t1_image,rm_in)\n",
    "    \n",
    "            images.append(rm_in)\n",
    "\n",
    "spm_proc = SPM(spm_path)\n",
    "cat_12_proc = spm_proc.cat12seg_imgs(images, tpm, template_volumes, run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*If you choose to run the previous step directly in MATLAB, you can run this in parallel*\n",
    "\n",
    "**This cell performs preprocessing steps on Diffusion Tensor Imaging (DTI)** data for each subject in a given directory. The steps involve:\n",
    "\n",
    "- Eddy current and movement correction via FSL (FreeSurfer)\n",
    "- Denoising through DIPY's patch2self method\n",
    "- Removal of Gibbs ringing artifacts.\n",
    "\n",
    "The result is *dti_eddy_denoised.nii.gz* that is placed under the *dti* directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-15T22:11:12.824442300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1080: Subject 0/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11409: Subject 1/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11446: Subject 2/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11453: Subject 3/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11460: Subject 4/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11477: Subject 5/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11495: Subject 6/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11627: Subject 7/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11731: Subject 8/221\n",
      "\n",
      "Processing 11732: Subject 9/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11766: Subject 10/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11778: Subject 11/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11782: Subject 12/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11797: Subject 13/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11841: Subject 14/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11862: Subject 15/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11879: Subject 16/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11904: Subject 17/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11913: Subject 18/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11950: Subject 19/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11962: Subject 20/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 11974: Subject 21/221\n",
      "\n",
      "Processing 12011: Subject 22/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13033: Subject 23/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13043: Subject 24/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13050: Subject 25/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13059: Subject 26/221\n",
      "Data shape: (128, 128, 2026) . Something is wrong with the shape of the data. Ignoring this image...\n",
      "\n",
      "Processing 13067: Subject 27/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 1307: Subject 28/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13076: Subject 29/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 13091: Subject 30/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 1389: Subject 31/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14091: Subject 32/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14093: Subject 33/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14120: Subject 34/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14121: Subject 35/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14122: Subject 36/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14123: Subject 37/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 14124: Subject 38/221\n",
      "\n",
      "Processing 1494: Subject 39/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15156: Subject 40/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15159: Subject 41/221\n",
      "\n",
      "Processing 15184: Subject 42/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15202: Subject 43/221\n",
      "\n",
      "Processing 15219: Subject 44/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15220: Subject 45/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15258: Subject 46/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15260: Subject 47/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15266: Subject 48/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15272: Subject 49/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15274: Subject 50/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15276: Subject 51/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15300: Subject 52/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15332: Subject 53/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15420: Subject 54/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15441: Subject 55/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15442: Subject 56/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15446: Subject 57/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15541: Subject 58/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15553: Subject 59/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15554: Subject 60/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15555: Subject 61/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15557: Subject 62/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15583: Subject 63/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15592: Subject 64/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15593: Subject 65/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15600: Subject 66/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15609: Subject 67/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15621: Subject 68/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15635: Subject 69/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15636: Subject 70/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15639: Subject 71/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15659: Subject 72/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15683: Subject 73/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15694: Subject 74/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15696: Subject 75/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15709: Subject 76/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15710: Subject 77/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15713: Subject 78/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15714: Subject 79/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15724: Subject 80/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15731: Subject 81/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15741: Subject 82/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15749: Subject 83/221\n",
      "\n",
      "Processing 15783: Subject 84/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15784: Subject 85/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15791: Subject 86/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15792: Subject 87/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15797: Subject 88/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15798: Subject 89/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15800: Subject 90/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15801: Subject 91/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15804: Subject 92/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15809: Subject 93/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15810: Subject 94/221\n",
      "\n",
      "Processing 15849: Subject 95/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15850: Subject 96/221\n",
      "\n",
      "Processing 15855: Subject 97/221\n",
      "\n",
      "Processing 15856: Subject 98/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15861: Subject 99/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15869: Subject 100/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 15914: Subject 101/221\n",
      "\n",
      "Processing 15958: Subject 102/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16018: Subject 103/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16072: Subject 104/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16084: Subject 105/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16088: Subject 106/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16098: Subject 107/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16109: Subject 108/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16131: Subject 109/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16146: Subject 110/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16149: Subject 111/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16160: Subject 112/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16161: Subject 113/221\n",
      "\n",
      "Processing 16206: Subject 114/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16219: Subject 115/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16227: Subject 116/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16233: Subject 117/221\n",
      "Result already exists!\n",
      "\n",
      "Processing 16236: Subject 118/221\n",
      "Data shape: (128, 128, 80, 33)\n",
      "Correcting DTI for eddy currents....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n"
     ]
    }
   ],
   "source": [
    "# DTI image preprocessing:\n",
    "# Eddy current and movement correction with FSL\n",
    "# Denoising using patch2self\n",
    "# Gibbs ring artifact correction\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.denoise.patch2self import patch2self\n",
    "from dipy.denoise.gibbs import gibbs_removal\n",
    "\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "for i in list_dirs:\n",
    "        \n",
    "    print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "    start_time = time.time()\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "\n",
    "    dti_image = False\n",
    "    bvec = False\n",
    "    bval = False\n",
    "    b_zero = False\n",
    "\n",
    "    files_ = os.listdir(dir_subj)\n",
    "\n",
    "    for file_ in files_:\n",
    "\n",
    "        if file_[0:2] == 'IN':\n",
    "            if file_[-4:] == 'bval':\n",
    "                bval = join(dir_subj, file_)\n",
    "            elif file_[-4:] == 'bvec':\n",
    "                bvec = join(dir_subj, file_)\n",
    "            elif file_[-3:] == 'nii':\n",
    "                if 'DTI' in file_:\n",
    "                    dti_image = join(dir_subj, file_)\n",
    "                    if 'DTI001' in file_:\n",
    "                        b_zero = 800\n",
    "                    else:\n",
    "                        b_zero = 1000\n",
    "\n",
    "    if dti_image and bvec and bval and b_zero:\n",
    "\n",
    "        dti_dir = join(dir_subj, 'dti')\n",
    "\n",
    "        dti_out = join(dti_dir,'dti_eddy_denoised.nii.gz')\n",
    "        \n",
    "        if exists(dti_out):\n",
    "            print(\"Result already exists!\")\n",
    "            b_file = join(dti_dir,str(b_zero))\n",
    "            with open(b_file, 'w') as b0_file:\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Check data 3D\n",
    "            data_ = nib.load(dti_image).get_fdata()\n",
    "            if len(data_.shape)!=4:\n",
    "                print(\"Data shape:\" ,  data_.shape, \". Something is wrong with the shape of the data. Ignoring this image...\")\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                print(\"Data shape:\" ,  data_.shape)\n",
    "\n",
    "                if not exists(dti_dir):\n",
    "                    os.makedirs(dti_dir)\n",
    "        \n",
    "                dti_in = join(dti_dir,'dti.nii')\n",
    "                shutil.copy(dti_image,dti_in)\n",
    "                \n",
    "                bval_in = join(dti_dir,'dti.bval')\n",
    "                shutil.copy(bval,bval_in)\n",
    "        \n",
    "                bvec_in = join(dti_dir,'dti.bvec')\n",
    "                shutil.copy(bvec,bvec_in)\n",
    "        \n",
    "                bvals, bvecs = read_bvals_bvecs(bval_in, bvec_in)\n",
    "                gtab = gradient_table(bvals, bvecs)\n",
    "        \n",
    "                dti_compressed = join(dti_dir,'dti_eddy.nii.gz')\n",
    "        \n",
    "                # Image Corrections\n",
    "                print(\"Correcting DTI for eddy currents....\")\n",
    "                log_file = join(dti_dir,'eddy_correct.log')\n",
    "                os.system('eddy_correct %s %s 0 spline >> %s' % (dti_in, dti_compressed, log_file))\n",
    "                \n",
    "                dti_img = nib.load(dti_compressed)\n",
    "                dti_data = dti_img.get_fdata()\n",
    "                hdr = dti_img.header\n",
    "                affine = dti_img.affine\n",
    "                \n",
    "                print(\"Denoising....\")\n",
    "                denoised_arr = patch2self(dti_data, bvals, model='ols', shift_intensity=True, clip_negative_vals=False, b0_threshold=50)\n",
    "                \n",
    "                print(\"Removing Gibbs artifacts....\")\n",
    "                gibbs_corr = gibbs_removal(denoised_arr, slice_axis=2, num_processes=-1)\n",
    "        \n",
    "                img = nib.Nifti1Image(gibbs_corr, affine, hdr)\n",
    "                nib.save(img, dti_out)\n",
    "                \n",
    "                b_file = join(dti_dir,str(b_zero))\n",
    "                with open(b_file, 'w') as b0_file:\n",
    "                    pass\n",
    "\n",
    "                print(\"I finished Processing %s: It took me %s minutes \" % (i, (time.time() - start_time) / 60))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This cell aims to correct distortions in the DTI dataset of each patient using 'dipy', 'nilearn', and 'nibabel' libraries along with ANTs software. \n",
    "\n",
    "*This needs the inputs from both previous cells (including the cat12 results) so wait those to finish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Registration-based distortion-correction:\n",
    "\n",
    "import nilearn.image as proc\n",
    "\n",
    "#Processing patients\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    output_file = join(dir_patients, i, 'dti', 'dti_ants.nii.gz')\n",
    "\n",
    "    if exists(output_file):\n",
    "        print('Patient %s is done' % i)\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        dir_subj = join(dir_patients,i)\n",
    "        print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "        start_time = time.time()\n",
    "    \n",
    "        dir_t1 = join(dir_subj, 'cat12','mri')\n",
    "        dir_dti = join(dir_subj,'dti')\n",
    "    \n",
    "        t1_source = join(dir_t1, 'p0t1.nii')\n",
    "        dti_source = join(dir_dti, 'dti_eddy_denoised.nii.gz')\n",
    "        \n",
    "        if exists(t1_source) and exists(dti_source):\n",
    "    \n",
    "            t1_img = nib.load(t1_source)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "            t1_data = t1_data.astype(float)\n",
    "            t1_img.set_data_dtype(float)\n",
    "        \n",
    "            indx = np.where(t1_data > 0)\n",
    "            t1_data[indx] = 1 / (t1_data[indx])\n",
    "        \n",
    "            inverted_t1 = nib.Nifti1Image(t1_data, t1_img.affine, t1_img.header)\n",
    "            inverted_t1 = proc.smooth_img(inverted_t1, 2)\n",
    "            inverted_name = join(dir_t1, 't1_inverted.nii.gz')\n",
    "            nib.save(inverted_t1, inverted_name)\n",
    "        \n",
    "            ants_log = 'ANTs_log.txt'\n",
    "        \n",
    "            img_4d = nib.load(dti_source)\n",
    "            # Get the 4D data array\n",
    "            data_4d = img_4d.get_fdata()\n",
    "            # Extract the first frame (3D) from the 4D data\n",
    "            data_3d = data_4d[:, :, :, 0]\n",
    "        \n",
    "            # Create a new 3D NIfTI image with the same header as the original 4D image\n",
    "            img_3d = nib.Nifti1Image(data_3d, img_4d.affine, img_4d.header)\n",
    "            b0 = join(dir_dti, 'b0.nii.gz')\n",
    "            nib.save(img_3d, b0)\n",
    "        \n",
    "            log = join(dir_subj, 'ants.log')\n",
    "        \n",
    "            print(\"Corregistering T1 with b0....\")\n",
    "        \n",
    "            command = 'antsRegistrationSyN.sh -d 3 -f %s -m %s -o %s/t1 -t r -n 6 > %s' % (b0, inverted_name, dir_t1, log)\n",
    "            os.system(command)\n",
    "        \n",
    "            print(\"Deforming b0....\")\n",
    "        \n",
    "            t1_warped = join(dir_t1,'t1Warped.nii.gz')\n",
    "        \n",
    "            command = 'antsRegistrationSyN.sh -d 3 -f %s -m %s -o %s/dti -t s -n 12 >> %s' % (t1_warped, b0, dir_dti, log)\n",
    "            os.system(command)\n",
    "        \n",
    "            dti_warped = join(dir_dti,'dtiWarped.nii.gz')\n",
    "            dti_warp = join(dir_dti,'dti1Warp.nii.gz')\n",
    "        \n",
    "            warped_files = []\n",
    "        \n",
    "            print(\"Applying the transformation to the whole dataset....\")\n",
    "        \n",
    "            for k in range(data_4d.shape[3]):\n",
    "                data_3d = data_4d[:, :, :, k]\n",
    "                img_3d = nib.Nifti1Image(data_3d, img_4d.affine, img_4d.header)\n",
    "                bk = join(dir_dti, 'temp_b%s.nii.gz' % k)\n",
    "                nib.save(img_3d, bk)\n",
    "                warped_bk = join(dir_dti, 'warped_b%s.nii.gz' % k)\n",
    "        \n",
    "                command = 'antsApplyTransforms -d 3 -i %s -r %s -o %s -t %s >> %s' % (bk, dti_warped, warped_bk, dti_warp, log)\n",
    "                os.system(command)\n",
    "        \n",
    "                warped_files.append(warped_bk)\n",
    "        \n",
    "            data_3d_list = [nib.load(file).get_fdata() for file in warped_files]\n",
    "        \n",
    "            data_4d = np.stack(data_3d_list, axis=3)\n",
    "        \n",
    "            affine = nib.load(warped_files[0]).affine\n",
    "            header = nib.load(warped_files[0]).header\n",
    "            header.set_data_shape(data_4d.shape)\n",
    "        \n",
    "            img_4d = nib.Nifti1Image(data_4d, affine, header)\n",
    "        \n",
    "            nib.save(img_4d, output_file)\n",
    "        \n",
    "            warped_t1 = join(dir_t1, 't1Warped.nii.gz')\n",
    "        \n",
    "            to_remove = join(dir_dti, 'temp_*')\n",
    "            os.system('rm %s' % to_remove)\n",
    "            to_remove = join(dir_dti, 'warped_*')\n",
    "            os.system('rm %s' % to_remove)\n",
    "        \n",
    "            print(\"I finished Processing %s: It took me %s minutes \" % (basename(dir_subj), (time.time() - start_time) / 60))\n",
    "        \n",
    "        else:\n",
    "            print(\"Images missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This script applies a brain mask to the 4D DTI images already preprocessed and corrected for distortion for each patient.\n",
    "**This needs the input data from the previous cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now we will mask data\n",
    "\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "    start_time = time.time()\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    dir_dti = join(dir_subj,'dti')\n",
    "\n",
    "    in_file = join(dir_dti, 'dti_ants.nii.gz')\n",
    "\n",
    "    out_mask = join(dir_dti, 'dti_mask.nii.gz')\n",
    "    out_masked = join(dir_dti, 'dti_masked.nii.gz')\n",
    "\n",
    "    if exists(in_file) and not exists(out_masked):\n",
    "\n",
    "        out = join(dir_dti, 'dti')\n",
    "        os.system('bet %s %s -m -f 0.2 -n' % (in_file, out))\n",
    "        \n",
    "        if exists(out_mask):\n",
    "\n",
    "            img_in = nib.load(in_file)\n",
    "            mask_in = nib.load(out_mask)\n",
    "\n",
    "            img_data = img_in.get_fdata()\n",
    "            mask_data = mask_in.get_fdata()\n",
    "            \n",
    "            mask_data = np.expand_dims(mask_data, axis=3)\n",
    "            masked_data = img_data * mask_data\n",
    "\n",
    "            img = nib.Nifti1Image(masked_data, img_in.affine, img_in.header)\n",
    "            nib.save(img, out_masked)\n",
    "\n",
    "        print(\"I finished Processing %s: It took me %s minutes \" % (i, (time.time() - start_time) / 60))\n",
    "\n",
    "    else:\n",
    "        print(\"I skipped this one. Already processed?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "Now you are ready to run the **Process_Cohort** script in the fw_pasternak directory.\n",
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "After Process_Cohort is done we can do some post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    dir_dti = join(dir_subj,'dti')\n",
    "    dir_t1 = join(dir_subj,'cat12','mri')\n",
    "    \n",
    "    \n",
    "    print('\\nPreparing postprocessing dirs %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "\n",
    "    results_dipy = ['dti_md.nii.gz', 'dti_fa.nii.gz']\n",
    "    results_pasternak = ['fw_FW.nii.gz','fw_NoNeg_MD.nii.gz', 'fw_NoNeg_FA.nii.gz', \n",
    "                         'fw_FWE.nii.gz', 'fw_FWE_MD.nii.gz', 'fw_FWE_FA.nii.gz']\n",
    "\n",
    "    for i in results_dipy:\n",
    "        \n",
    "        result = join(dir_dti,i)\n",
    "        warp = join(dir_t1,'t10GenericAffine.mat')\n",
    "        t1_inverted = join(dir_t1,'t1_inverted.nii.gz')\n",
    "        out_ants = join(dir_dti,'t1_%s' % i)\n",
    "\n",
    "        if exists(result):\n",
    "\n",
    "            command='antsApplyTransforms -d 3 -i %s -r %s -o %s -t [%s,1]' % (result, t1_inverted, out_ants, warp)\n",
    "            os.system(command)\n",
    "    \n",
    "            with gzip.open(out_ants, 'rb') as f_in:\n",
    "                with open(out_ants[0:-3], 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "                    \n",
    "            os.remove(out_ants)\n",
    "        \n",
    "        else:\n",
    "            print('Some file missing')\n",
    "\n",
    "    img_to_deform = []\n",
    "    \n",
    "    for i in results_dipy:\n",
    "        \n",
    "        out_ants = 't1_%s' % i[0:-3]\n",
    "        in_docker = join('/dti_data',out_ants)\n",
    "        \n",
    "        if exists(join(dir_dti,out_ants)):\n",
    "            img_to_deform.append(in_docker)\n",
    "\n",
    "    if img_to_deform:\n",
    "\n",
    "        def_matrix = join('/mri_data', 'y_t1.nii')\n",
    "    \n",
    "        mfile_name = join(dir_dti, 'deformations.m')\n",
    "    \n",
    "        design_type_comp = \"matlabbatch{1}.spm.util.defs.comp{1}.\"\n",
    "        design_type_out = \"matlabbatch{1}.spm.util.defs.out{1}.\"\n",
    "    \n",
    "        new_spm = open(mfile_name, \"w\")\n",
    "    \n",
    "        new_spm.write(\n",
    "                design_type_comp + \"def = {'\" + '/mri_data/y_t1.nii' + \"'};\\n\" +\n",
    "                design_type_out + \"pull.fnames = {\" + \"\\n\")\n",
    "    \n",
    "        for image in img_to_deform:\n",
    "            new_spm.write(\"'\" + image + \"'\\n\")\n",
    "        new_spm.write(\"};\\n\")\n",
    "    \n",
    "        new_spm.write(\n",
    "            design_type_out + \"pull.savedir.savesrc = 1;\\n\" +\n",
    "            design_type_out + \"pull.interp =\" + str(4) + \";\\n\" +\n",
    "            design_type_out + \"pull.mask = 0;\\n\" +\n",
    "            design_type_out + \"pull.fwhm = [0 0 0];\\n\" +\n",
    "            design_type_out + \"pull.prefix ='\" + 'w' + \"';\\n\"\n",
    "            )\n",
    "    \n",
    "        new_spm.close()\n",
    "    \n",
    "        client.containers.run(image=\"jhuguetn/cat12\", auto_remove=True, tty=True, stdin_open=True,\n",
    "                                volumes={dir_dti: {\"bind\": \"/dti_data\", \"mode\": \"rw\"},\n",
    "                                        dir_t1: {\"bind\": \"/mri_data\", \"mode\": \"rw\"}},\n",
    "                                command=\"-b /dti_data/deformations.m\")\n",
    "\n",
    "\n",
    "    for i in results_pasternak:\n",
    "        \n",
    "        result = join(dir_dti,'Pasternak',i)\n",
    "        warp = join(dir_t1,'t10GenericAffine.mat')\n",
    "        t1_inverted = join(dir_t1,'t1_inverted.nii.gz')\n",
    "        out_ants = join(dir_dti,'t1_%s' % i)\n",
    "\n",
    "        if exists(result):\n",
    "\n",
    "            command='antsApplyTransforms -d 3 -i %s -r %s -o %s -t [%s,1]' % (result, t1_inverted, out_ants, warp)\n",
    "            os.system(command)\n",
    "    \n",
    "            with gzip.open(out_ants, 'rb') as f_in:\n",
    "                with open(out_ants[0:-3], 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "                    \n",
    "            os.remove(out_ants)\n",
    "        \n",
    "        else:\n",
    "            print('Some file missing')\n",
    "\n",
    "    img_to_deform = []\n",
    "    \n",
    "    for i in results_pasternak:\n",
    "        \n",
    "        out_ants = 't1_%s' % i[0:-3]\n",
    "        in_docker = join('/dti_data',out_ants)\n",
    "        \n",
    "        if exists(join(dir_dti,out_ants)):\n",
    "            img_to_deform.append(in_docker)\n",
    "\n",
    "    if img_to_deform:\n",
    "\n",
    "        def_matrix = join('/mri_data', 'y_t1.nii')\n",
    "    \n",
    "        mfile_name = join(dir_dti, 'deformations.m')\n",
    "    \n",
    "        design_type_comp = \"matlabbatch{1}.spm.util.defs.comp{1}.\"\n",
    "        design_type_out = \"matlabbatch{1}.spm.util.defs.out{1}.\"\n",
    "    \n",
    "        new_spm = open(mfile_name, \"w\")\n",
    "    \n",
    "        new_spm.write(\n",
    "                design_type_comp + \"def = {'\" + '/mri_data/y_t1.nii' + \"'};\\n\" +\n",
    "                design_type_out + \"pull.fnames = {\" + \"\\n\")\n",
    "    \n",
    "        for image in img_to_deform:\n",
    "            new_spm.write(\"'\" + image + \"'\\n\")\n",
    "        new_spm.write(\"};\\n\")\n",
    "    \n",
    "        new_spm.write(\n",
    "            design_type_out + \"pull.savedir.savesrc = 1;\\n\" +\n",
    "            design_type_out + \"pull.interp =\" + str(4) + \";\\n\" +\n",
    "            design_type_out + \"pull.mask = 0;\\n\" +\n",
    "            design_type_out + \"pull.fwhm = [0 0 0];\\n\" +\n",
    "            design_type_out + \"pull.prefix ='\" + 'w' + \"';\\n\"\n",
    "            )\n",
    "    \n",
    "        new_spm.close()\n",
    "    \n",
    "        client.containers.run(image=\"jhuguetn/cat12\", auto_remove=True, tty=True, stdin_open=True,\n",
    "                                volumes={dir_dti: {\"bind\": \"/dti_data\", \"mode\": \"rw\"},\n",
    "                                        dir_t1: {\"bind\": \"/mri_data\", \"mode\": \"rw\"}},\n",
    "                                command=\"-b /dti_data/deformations.m\")\n",
    "\n",
    "    os.system('rm %s/t1_*' % dir_dti)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
