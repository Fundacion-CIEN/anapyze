{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Sets directories:\n",
    "   - `anapyze_dir`: Directory where the anapyze_directory is located\n",
    "   - `spm_path`: Path for your installation of the Statistical Parametric Mapping (SPM) software "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:30:21.661394073Z",
     "start_time": "2023-08-18T09:30:21.656146180Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import shutil\n",
    "import gzip\n",
    "import nibabel as nib\n",
    "from os.path import join, exists, isdir, basename\n",
    "import numpy as np\n",
    "import time\n",
    "import docker\n",
    "\n",
    "anapyze_dir = r'/home/jsilva/Work/txusser/anapyze' \n",
    "anapyze_rsc = join(anapyze_dir,'resources')\n",
    "sys.path.insert(0,anapyze_dir)\n",
    "\n",
    "spm_path = r'/home/jsilva/Software/spm12' # Must have cat12\n",
    "from spm import spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Sets directories:\n",
    "   - **Patient Data Directory (dir_patients):** This points to the directory where patient data is stored. *Note that this script expects that you have run the 0_Reorder_Data.py first*\n",
    "\n",
    "**Template Images:**\n",
    "   - **TPM (Tissue Probability Maps) Image (tpm):** This is set to the path where the TPM.nii file resides within the SPM software directory. **Check that this is correct**. \n",
    "\n",
    "   - **CAT12 Gray Scale Template Volume (template_volumes):** This is set to the path in the SPM directory where the CAT12 toolbox's template volumes are stored. **Check that this is correct**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:30:23.088125733Z",
     "start_time": "2023-08-18T09:30:23.086067271Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your data directory here\n",
    "dir_patients = r'/home/jsilva/Data/IBIS_DATA/Reorder_All'\n",
    "\n",
    "# Change your templates here if necessary\n",
    "tpm = join(spm_path,'tpm','TPM.nii')\n",
    "template_volumes = join(spm_path,'toolbox','cat12','templates_MNI152NLin2009cAsym','Template_0_GS.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This prepares a processing script that will process the collected T1 image files using SPM's CAT12 toolbox.\n",
    "\n",
    "A MATLAB script named 'cat_12.m' is created which has to be run separately in MATLAB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "#This will create a cat_12.m file that must be run on MATLAB separately\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    check_cat_proceesing = join(dir_subj, 'cat12', 'report', 'catreport_t1.pdf')\n",
    "    \n",
    "    if exists(check_cat_proceesing):\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        t1_image = False\n",
    "        \n",
    "        files_ = os.listdir(dir_subj)\n",
    "    \n",
    "        for file_ in files_:\n",
    "    \n",
    "            if file_[0:2] == 'IN':\n",
    "                if file_[-3:] == 'nii':\n",
    "                    if 'T1' in file_:\n",
    "                        t1_image = join(dir_subj, file_)\n",
    "                        \n",
    "        if t1_image:\n",
    "            \n",
    "            cat12_dir = join(dir_subj, 'cat12')\n",
    "            \n",
    "            if not exists(cat12_dir):\n",
    "                os.makedirs(cat12_dir)\n",
    "    \n",
    "            rm_in = join(cat12_dir,'t1.nii')\n",
    "            shutil.copy(t1_image,rm_in)\n",
    "    \n",
    "            images.append(rm_in)\n",
    "\n",
    "spm_proc = spm(spm_path)\n",
    "cat_12_proc = spm_proc.cat12seg_imgs(images, tpm, template_volumes)\n",
    "\n",
    "#This will create a cat_12.m file that must can run on MATLAB separately\n",
    "#Alternatively you can uncomment the next line\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**You can run this in parallel with the cat12 processing from the previous cell\n",
    "\n",
    "This script performs preprocessing steps on Diffusion Tensor Imaging (DTI) data for each subject in a given directory. The steps involve:\n",
    "\n",
    "- Eddy current and movement correction via FSL (FreeSurfer)\n",
    "- Denoising through DIPY's patch2self method\n",
    "- Removal of Gibbs ringing artifacts.\n",
    "\n",
    "The result is *dti_eddy_denoised.nii.gz* that is placed under the *dti* directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DTI image preprocessing:\n",
    "# Eddy current and movement correction with FSL\n",
    "# Denoising using patch2self\n",
    "# Gibbs ring artifact correction\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.denoise.patch2self import patch2self\n",
    "from dipy.denoise.gibbs import gibbs_removal\n",
    "\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "for i in list_dirs:\n",
    "        \n",
    "    print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "    start_time = time.time()\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "\n",
    "    dti_image = False\n",
    "    bvec = False\n",
    "    bval = False\n",
    "    b_zero = False\n",
    "\n",
    "    files_ = os.listdir(dir_subj)\n",
    "\n",
    "    for file_ in files_:\n",
    "\n",
    "        if file_[0:2] == 'IN':\n",
    "            if file_[-4:] == 'bval':\n",
    "                bval = join(dir_subj, file_)\n",
    "            elif file_[-4:] == 'bvec':\n",
    "                bvec = join(dir_subj, file_)\n",
    "            elif file_[-3:] == 'nii':\n",
    "                if 'DTI' in file_:\n",
    "                    dti_image = join(dir_subj, file_)\n",
    "                    if 'DTI001' in file_:\n",
    "                        b_zero = 800\n",
    "                    else:\n",
    "                        b_zero = 1000\n",
    "\n",
    "    if dti_image and bvec and bval and b_zero:\n",
    "\n",
    "        dti_dir = join(dir_subj, 'dti')\n",
    "\n",
    "        dti_out = join(dti_dir,'dti_eddy_denoised.nii.gz')\n",
    "        \n",
    "        if exists(dti_out):\n",
    "            print(\"Result already exists!\")\n",
    "            b_file = join(dti_dir,str(b_zero))\n",
    "            with open(b_file, 'w') as b0_file:\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Check data 3D\n",
    "            data_ = nib.load(dti_image).get_fdata()\n",
    "            if len(data_.shape)!=4:\n",
    "                print(\"Data shape:\" ,  data_.shape, \". Something is wrong with the shape of the data. Ignoring this image...\")\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                print(\"Data shape:\" ,  data_.shape)\n",
    "\n",
    "                if not exists(dti_dir):\n",
    "                    os.makedirs(dti_dir)\n",
    "        \n",
    "                dti_in = join(dti_dir,'dti.nii')\n",
    "                shutil.copy(dti_image,dti_in)\n",
    "                \n",
    "                bval_in = join(dti_dir,'dti.bval')\n",
    "                shutil.copy(bval,bval_in)\n",
    "        \n",
    "                bvec_in = join(dti_dir,'dti.bvec')\n",
    "                shutil.copy(bvec,bvec_in)\n",
    "        \n",
    "                bvals, bvecs = read_bvals_bvecs(bval_in, bvec_in)\n",
    "                gtab = gradient_table(bvals, bvecs)\n",
    "        \n",
    "                dti_compressed = join(dti_dir,'dti_eddy.nii.gz')\n",
    "        \n",
    "                # Image Corrections\n",
    "                print(\"Correcting DTI for eddy currents....\")\n",
    "                log_file = join(dti_dir,'eddy_correct.log')\n",
    "                os.system('eddy_correct %s %s 0 spline >> %s' % (dti_in, dti_compressed, log_file))\n",
    "                \n",
    "                dti_img = nib.load(dti_compressed)\n",
    "                dti_data = dti_img.get_fdata()\n",
    "                hdr = dti_img.header\n",
    "                affine = dti_img.affine\n",
    "                \n",
    "                print(\"Denoising....\")\n",
    "                denoised_arr = patch2self(dti_data, bvals, model='ols', shift_intensity=True, clip_negative_vals=False, b0_threshold=50)\n",
    "                \n",
    "                print(\"Removing Gibbs artifacts....\")\n",
    "                gibbs_corr = gibbs_removal(denoised_arr, slice_axis=2, num_processes=-1)\n",
    "        \n",
    "                img = nib.Nifti1Image(gibbs_corr, affine, hdr)\n",
    "                nib.save(img, dti_out)\n",
    "                \n",
    "                b_file = join(dti_dir,str(b_zero))\n",
    "                with open(b_file, 'w') as b0_file:\n",
    "                    pass\n",
    "\n",
    "                print(\"I finished Processing %s: It took me %s minutes \" % (i, (time.time() - start_time) / 60))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This cell aims to correct distortions in the DTI dataset of each patient using 'dipy', 'nilearn', and 'nibabel' libraries along with ANTs software. \n",
    "\n",
    "*This needs the inputs from both previous cells (including the cat12 results) so wait those to finish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Registration-based distortion-correction:\n",
    "\n",
    "import nilearn.image as proc\n",
    "\n",
    "#Processing patients\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    output_file = join(dir_patients, i, 'dti', 'dti_ants.nii.gz')\n",
    "\n",
    "    if exists(output_file):\n",
    "        print('Patient %s is done' % i)\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        dir_subj = join(dir_patients,i)\n",
    "        print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "        start_time = time.time()\n",
    "    \n",
    "        dir_t1 = join(dir_subj, 'cat12','mri')\n",
    "        dir_dti = join(dir_subj,'dti')\n",
    "    \n",
    "        t1_source = join(dir_t1, 'p0t1.nii')\n",
    "        dti_source = join(dir_dti, 'dti_eddy_denoised.nii.gz')\n",
    "        \n",
    "        if exists(t1_source) and exists(dti_source):\n",
    "    \n",
    "            t1_img = nib.load(t1_source)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "            t1_data = t1_data.astype(float)\n",
    "            t1_img.set_data_dtype(float)\n",
    "        \n",
    "            indx = np.where(t1_data > 0)\n",
    "            t1_data[indx] = 1 / (t1_data[indx])\n",
    "        \n",
    "            inverted_t1 = nib.Nifti1Image(t1_data, t1_img.affine, t1_img.header)\n",
    "            inverted_t1 = proc.smooth_img(inverted_t1, 2)\n",
    "            inverted_name = join(dir_t1, 't1_inverted.nii.gz')\n",
    "            nib.save(inverted_t1, inverted_name)\n",
    "        \n",
    "            ants_log = 'ANTs_log.txt'\n",
    "        \n",
    "            img_4d = nib.load(dti_source)\n",
    "            # Get the 4D data array\n",
    "            data_4d = img_4d.get_fdata()\n",
    "            # Extract the first frame (3D) from the 4D data\n",
    "            data_3d = data_4d[:, :, :, 0]\n",
    "        \n",
    "            # Create a new 3D NIfTI image with the same header as the original 4D image\n",
    "            img_3d = nib.Nifti1Image(data_3d, img_4d.affine, img_4d.header)\n",
    "            b0 = join(dir_dti, 'b0.nii.gz')\n",
    "            nib.save(img_3d, b0)\n",
    "        \n",
    "            log = join(dir_subj, 'ants.log')\n",
    "        \n",
    "            print(\"Corregistering T1 with b0....\")\n",
    "        \n",
    "            command = 'antsRegistrationSyN.sh -d 3 -f %s -m %s -o %s/t1 -t r -n 6 > %s' % (b0, inverted_name, dir_t1, log)\n",
    "            os.system(command)\n",
    "        \n",
    "            print(\"Deforming b0....\")\n",
    "        \n",
    "            t1_warped = join(dir_t1,'t1Warped.nii.gz')\n",
    "        \n",
    "            command = 'antsRegistrationSyN.sh -d 3 -f %s -m %s -o %s/dti -t s -n 12 >> %s' % (t1_warped, b0, dir_dti, log)\n",
    "            os.system(command)\n",
    "        \n",
    "            dti_warped = join(dir_dti,'dtiWarped.nii.gz')\n",
    "            dti_warp = join(dir_dti,'dti1Warp.nii.gz')\n",
    "        \n",
    "            warped_files = []\n",
    "        \n",
    "            print(\"Applying the transformation to the whole dataset....\")\n",
    "        \n",
    "            for k in range(data_4d.shape[3]):\n",
    "                data_3d = data_4d[:, :, :, k]\n",
    "                img_3d = nib.Nifti1Image(data_3d, img_4d.affine, img_4d.header)\n",
    "                bk = join(dir_dti, 'temp_b%s.nii.gz' % k)\n",
    "                nib.save(img_3d, bk)\n",
    "                warped_bk = join(dir_dti, 'warped_b%s.nii.gz' % k)\n",
    "        \n",
    "                command = 'antsApplyTransforms -d 3 -i %s -r %s -o %s -t %s >> %s' % (bk, dti_warped, warped_bk, dti_warp, log)\n",
    "                os.system(command)\n",
    "        \n",
    "                warped_files.append(warped_bk)\n",
    "        \n",
    "            data_3d_list = [nib.load(file).get_fdata() for file in warped_files]\n",
    "        \n",
    "            data_4d = np.stack(data_3d_list, axis=3)\n",
    "        \n",
    "            affine = nib.load(warped_files[0]).affine\n",
    "            header = nib.load(warped_files[0]).header\n",
    "            header.set_data_shape(data_4d.shape)\n",
    "        \n",
    "            img_4d = nib.Nifti1Image(data_4d, affine, header)\n",
    "        \n",
    "            nib.save(img_4d, output_file)\n",
    "        \n",
    "            warped_t1 = join(dir_t1, 't1Warped.nii.gz')\n",
    "        \n",
    "            to_remove = join(dir_dti, 'temp_*')\n",
    "            os.system('rm %s' % to_remove)\n",
    "            to_remove = join(dir_dti, 'warped_*')\n",
    "            os.system('rm %s' % to_remove)\n",
    "        \n",
    "            print(\"I finished Processing %s: It took me %s minutes \" % (basename(dir_subj), (time.time() - start_time) / 60))\n",
    "        \n",
    "        else:\n",
    "            print(\"Images missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This script applies a brain mask to the 4D DTI images already preprocessed and corrected for distortion for each patient.\n",
    "**This needs the input data from the previous cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:30:57.255328569Z",
     "start_time": "2023-08-18T09:30:57.213617792Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1080: Subject 0/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11409: Subject 1/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11446: Subject 2/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11453: Subject 3/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11460: Subject 4/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11477: Subject 5/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11495: Subject 6/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11627: Subject 7/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11731: Subject 8/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11732: Subject 9/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11766: Subject 10/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11778: Subject 11/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11782: Subject 12/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11797: Subject 13/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11841: Subject 14/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11862: Subject 15/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11879: Subject 16/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11904: Subject 17/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11913: Subject 18/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11950: Subject 19/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11974: Subject 20/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 12011: Subject 21/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13033: Subject 22/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13043: Subject 23/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13050: Subject 24/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13059: Subject 25/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13067: Subject 26/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 1307: Subject 27/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13076: Subject 28/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 13091: Subject 29/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 1389: Subject 30/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14091: Subject 31/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14093: Subject 32/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14120: Subject 33/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14121: Subject 34/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14122: Subject 35/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14123: Subject 36/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 14124: Subject 37/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 1494: Subject 38/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15156: Subject 39/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15184: Subject 40/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15219: Subject 41/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15220: Subject 42/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15258: Subject 43/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15260: Subject 44/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15266: Subject 45/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15272: Subject 46/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15274: Subject 47/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15276: Subject 48/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15300: Subject 49/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15332: Subject 50/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15420: Subject 51/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15441: Subject 52/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15442: Subject 53/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15446: Subject 54/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15457: Subject 55/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15541: Subject 56/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15553: Subject 57/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15554: Subject 58/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15555: Subject 59/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15583: Subject 60/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15592: Subject 61/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15593: Subject 62/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15600: Subject 63/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15609: Subject 64/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15621: Subject 65/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15635: Subject 66/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15636: Subject 67/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15639: Subject 68/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15659: Subject 69/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15683: Subject 70/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15694: Subject 71/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15696: Subject 72/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15709: Subject 73/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15710: Subject 74/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15713: Subject 75/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15714: Subject 76/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15724: Subject 77/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15731: Subject 78/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15741: Subject 79/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15784: Subject 80/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15791: Subject 81/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15792: Subject 82/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15797: Subject 83/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15798: Subject 84/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15800: Subject 85/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15801: Subject 86/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15804: Subject 87/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15809: Subject 88/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15810: Subject 89/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15849: Subject 90/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15850: Subject 91/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15855: Subject 92/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15856: Subject 93/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15861: Subject 94/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15869: Subject 95/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15914: Subject 96/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15958: Subject 97/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16018: Subject 98/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16072: Subject 99/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 11962: Subject 100/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15159: Subject 101/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15557: Subject 102/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 15783: Subject 103/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16084: Subject 104/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16453: Subject 105/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16690: Subject 106/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16088: Subject 107/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16098: Subject 108/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16109: Subject 109/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16131: Subject 110/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16146: Subject 111/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16149: Subject 112/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16160: Subject 113/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16206: Subject 114/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16219: Subject 115/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16227: Subject 116/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16233: Subject 117/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16272: Subject 118/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16276: Subject 119/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16312: Subject 120/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16318: Subject 121/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16320: Subject 122/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16343: Subject 123/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16360: Subject 124/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16388: Subject 125/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16399: Subject 126/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16513: Subject 127/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16522: Subject 128/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16545: Subject 129/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16548: Subject 130/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16551: Subject 131/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16552: Subject 132/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16617: Subject 133/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16636: Subject 134/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16637: Subject 135/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16638: Subject 136/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16639: Subject 137/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16654: Subject 138/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16655: Subject 139/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16658: Subject 140/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16662: Subject 141/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16666: Subject 142/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16667: Subject 143/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16681: Subject 144/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16686: Subject 145/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16689: Subject 146/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16691: Subject 147/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16716: Subject 148/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16722: Subject 149/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16732: Subject 150/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16750: Subject 151/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16761: Subject 152/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16790: Subject 153/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 16881: Subject 154/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 1761: Subject 155/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 2858: Subject 156/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 3535: Subject 157/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 3974: Subject 158/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 4334: Subject 159/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 4507: Subject 160/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5209: Subject 161/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5212: Subject 162/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5660: Subject 163/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5736: Subject 164/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5746: Subject 165/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 5817: Subject 166/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6081: Subject 167/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6147: Subject 168/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6148: Subject 169/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6257: Subject 170/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6323: Subject 171/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6406: Subject 172/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6830: Subject 173/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6895: Subject 174/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6903: Subject 175/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 6968: Subject 176/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 8061: Subject 177/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 8079: Subject 178/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 9037: Subject 179/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 9071: Subject 180/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 9114: Subject 181/183\n",
      "I skipped this one. Already processed?\n",
      "\n",
      "Processing 9314: Subject 182/183\n",
      "I skipped this one. Already processed?\n"
     ]
    }
   ],
   "source": [
    "#Now we will mask data\n",
    "\n",
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    print('\\nProcessing %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "    start_time = time.time()\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    dir_dti = join(dir_subj,'dti')\n",
    "\n",
    "    in_file = join(dir_dti, 'dti_ants.nii.gz')\n",
    "\n",
    "    out_mask = join(dir_dti, 'dti_mask.nii.gz')\n",
    "    out_masked = join(dir_dti, 'dti_masked.nii.gz')\n",
    "\n",
    "    if exists(in_file) and not exists(out_masked):\n",
    "\n",
    "        out = join(dir_dti, 'dti')\n",
    "        os.system('bet %s %s -m -f 0.2 -n' % (in_file, out))\n",
    "        \n",
    "        if exists(out_mask):\n",
    "\n",
    "            img_in = nib.load(in_file)\n",
    "            mask_in = nib.load(out_mask)\n",
    "\n",
    "            img_data = img_in.get_fdata()\n",
    "            mask_data = mask_in.get_fdata()\n",
    "            \n",
    "            mask_data = np.expand_dims(mask_data, axis=3)\n",
    "            masked_data = img_data * mask_data\n",
    "\n",
    "            img = nib.Nifti1Image(masked_data, img_in.affine, img_in.header)\n",
    "            nib.save(img, out_masked)\n",
    "\n",
    "        print(\"I finished Processing %s: It took me %s minutes \" % (i, (time.time() - start_time) / 60))\n",
    "\n",
    "    else:\n",
    "        print(\"I skipped this one. Already processed?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "Now you are ready to run the **Process_Cohort** script in the fw_pasternak directory.\n",
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "After Process_Cohort is done we can do some post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:55:26.012779167Z",
     "start_time": "2023-08-18T09:55:25.990017906Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 1080: Subject 0/183\n",
      "\n",
      "Preparing postprocessing dirs 11409: Subject 1/183\n",
      "\n",
      "Preparing postprocessing dirs 11446: Subject 2/183\n",
      "\n",
      "Preparing postprocessing dirs 11453: Subject 3/183\n",
      "\n",
      "Preparing postprocessing dirs 11460: Subject 4/183\n",
      "\n",
      "Preparing postprocessing dirs 11477: Subject 5/183\n",
      "\n",
      "Preparing postprocessing dirs 11495: Subject 6/183\n",
      "\n",
      "Preparing postprocessing dirs 11627: Subject 7/183\n",
      "\n",
      "Preparing postprocessing dirs 11731: Subject 8/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 11732: Subject 9/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/11731/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 11766: Subject 10/183\n",
      "\n",
      "Preparing postprocessing dirs 11778: Subject 11/183\n",
      "\n",
      "Preparing postprocessing dirs 11782: Subject 12/183\n",
      "\n",
      "Preparing postprocessing dirs 11797: Subject 13/183\n",
      "\n",
      "Preparing postprocessing dirs 11841: Subject 14/183\n",
      "\n",
      "Preparing postprocessing dirs 11862: Subject 15/183\n",
      "\n",
      "Preparing postprocessing dirs 11879: Subject 16/183\n",
      "\n",
      "Preparing postprocessing dirs 11904: Subject 17/183\n",
      "\n",
      "Preparing postprocessing dirs 11913: Subject 18/183\n",
      "\n",
      "Preparing postprocessing dirs 11950: Subject 19/183\n",
      "\n",
      "Preparing postprocessing dirs 11974: Subject 20/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 12011: Subject 21/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/11974/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 13033: Subject 22/183\n",
      "\n",
      "Preparing postprocessing dirs 13043: Subject 23/183\n",
      "\n",
      "Preparing postprocessing dirs 13050: Subject 24/183\n",
      "\n",
      "Preparing postprocessing dirs 13059: Subject 25/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 13067: Subject 26/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/13059/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 1307: Subject 27/183\n",
      "\n",
      "Preparing postprocessing dirs 13076: Subject 28/183\n",
      "\n",
      "Preparing postprocessing dirs 13091: Subject 29/183\n",
      "\n",
      "Preparing postprocessing dirs 1389: Subject 30/183\n",
      "\n",
      "Preparing postprocessing dirs 14091: Subject 31/183\n",
      "\n",
      "Preparing postprocessing dirs 14093: Subject 32/183\n",
      "\n",
      "Preparing postprocessing dirs 14120: Subject 33/183\n",
      "\n",
      "Preparing postprocessing dirs 14121: Subject 34/183\n",
      "\n",
      "Preparing postprocessing dirs 14122: Subject 35/183\n",
      "\n",
      "Preparing postprocessing dirs 14123: Subject 36/183\n",
      "\n",
      "Preparing postprocessing dirs 14124: Subject 37/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 1494: Subject 38/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/14124/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 15156: Subject 39/183\n",
      "\n",
      "Preparing postprocessing dirs 15184: Subject 40/183\n",
      "\n",
      "Preparing postprocessing dirs 15219: Subject 41/183\n",
      "\n",
      "Preparing postprocessing dirs 15220: Subject 42/183\n",
      "\n",
      "Preparing postprocessing dirs 15258: Subject 43/183\n",
      "\n",
      "Preparing postprocessing dirs 15260: Subject 44/183\n",
      "\n",
      "Preparing postprocessing dirs 15266: Subject 45/183\n",
      "\n",
      "Preparing postprocessing dirs 15272: Subject 46/183\n",
      "\n",
      "Preparing postprocessing dirs 15274: Subject 47/183\n",
      "\n",
      "Preparing postprocessing dirs 15276: Subject 48/183\n",
      "\n",
      "Preparing postprocessing dirs 15300: Subject 49/183\n",
      "\n",
      "Preparing postprocessing dirs 15332: Subject 50/183\n",
      "\n",
      "Preparing postprocessing dirs 15420: Subject 51/183\n",
      "\n",
      "Preparing postprocessing dirs 15441: Subject 52/183\n",
      "\n",
      "Preparing postprocessing dirs 15442: Subject 53/183\n",
      "\n",
      "Preparing postprocessing dirs 15446: Subject 54/183\n",
      "\n",
      "Preparing postprocessing dirs 15457: Subject 55/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15541: Subject 56/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15457/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 15553: Subject 57/183\n",
      "\n",
      "Preparing postprocessing dirs 15554: Subject 58/183\n",
      "\n",
      "Preparing postprocessing dirs 15555: Subject 59/183\n",
      "\n",
      "Preparing postprocessing dirs 15583: Subject 60/183\n",
      "\n",
      "Preparing postprocessing dirs 15592: Subject 61/183\n",
      "\n",
      "Preparing postprocessing dirs 15593: Subject 62/183\n",
      "\n",
      "Preparing postprocessing dirs 15600: Subject 63/183\n",
      "\n",
      "Preparing postprocessing dirs 15609: Subject 64/183\n",
      "\n",
      "Preparing postprocessing dirs 15621: Subject 65/183\n",
      "\n",
      "Preparing postprocessing dirs 15635: Subject 66/183\n",
      "\n",
      "Preparing postprocessing dirs 15636: Subject 67/183\n",
      "\n",
      "Preparing postprocessing dirs 15639: Subject 68/183\n",
      "\n",
      "Preparing postprocessing dirs 15659: Subject 69/183\n",
      "\n",
      "Preparing postprocessing dirs 15683: Subject 70/183\n",
      "\n",
      "Preparing postprocessing dirs 15694: Subject 71/183\n",
      "\n",
      "Preparing postprocessing dirs 15696: Subject 72/183\n",
      "\n",
      "Preparing postprocessing dirs 15709: Subject 73/183\n",
      "\n",
      "Preparing postprocessing dirs 15710: Subject 74/183\n",
      "\n",
      "Preparing postprocessing dirs 15713: Subject 75/183\n",
      "\n",
      "Preparing postprocessing dirs 15714: Subject 76/183\n",
      "\n",
      "Preparing postprocessing dirs 15724: Subject 77/183\n",
      "\n",
      "Preparing postprocessing dirs 15731: Subject 78/183\n",
      "\n",
      "Preparing postprocessing dirs 15741: Subject 79/183\n",
      "\n",
      "Preparing postprocessing dirs 15784: Subject 80/183\n",
      "\n",
      "Preparing postprocessing dirs 15791: Subject 81/183\n",
      "\n",
      "Preparing postprocessing dirs 15792: Subject 82/183\n",
      "\n",
      "Preparing postprocessing dirs 15797: Subject 83/183\n",
      "\n",
      "Preparing postprocessing dirs 15798: Subject 84/183\n",
      "\n",
      "Preparing postprocessing dirs 15800: Subject 85/183\n",
      "\n",
      "Preparing postprocessing dirs 15801: Subject 86/183\n",
      "\n",
      "Preparing postprocessing dirs 15804: Subject 87/183\n",
      "\n",
      "Preparing postprocessing dirs 15809: Subject 88/183\n",
      "\n",
      "Preparing postprocessing dirs 15810: Subject 89/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15849: Subject 90/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15810/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 15850: Subject 91/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15855: Subject 92/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15856: Subject 93/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15850/dti/t1_*': No existe el archivo o el directorio\n",
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15855/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 15861: Subject 94/183\n",
      "\n",
      "Preparing postprocessing dirs 15869: Subject 95/183\n",
      "\n",
      "Preparing postprocessing dirs 15914: Subject 96/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15958: Subject 97/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15914/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 16018: Subject 98/183\n",
      "\n",
      "Preparing postprocessing dirs 16072: Subject 99/183\n",
      "\n",
      "Preparing postprocessing dirs 11962: Subject 100/183\n",
      "\n",
      "Preparing postprocessing dirs 15159: Subject 101/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 15557: Subject 102/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/15159/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 15783: Subject 103/183\n",
      "\n",
      "Preparing postprocessing dirs 16084: Subject 104/183\n",
      "\n",
      "Preparing postprocessing dirs 16453: Subject 105/183\n",
      "\n",
      "Preparing postprocessing dirs 16690: Subject 106/183\n",
      "\n",
      "Preparing postprocessing dirs 16088: Subject 107/183\n",
      "\n",
      "Preparing postprocessing dirs 16098: Subject 108/183\n",
      "\n",
      "Preparing postprocessing dirs 16109: Subject 109/183\n",
      "\n",
      "Preparing postprocessing dirs 16131: Subject 110/183\n",
      "\n",
      "Preparing postprocessing dirs 16146: Subject 111/183\n",
      "\n",
      "Preparing postprocessing dirs 16149: Subject 112/183\n",
      "\n",
      "Preparing postprocessing dirs 16160: Subject 113/183\n",
      "\n",
      "Preparing postprocessing dirs 16206: Subject 114/183\n",
      "\n",
      "Preparing postprocessing dirs 16219: Subject 115/183\n",
      "\n",
      "Preparing postprocessing dirs 16227: Subject 116/183\n",
      "\n",
      "Preparing postprocessing dirs 16233: Subject 117/183\n",
      "\n",
      "Preparing postprocessing dirs 16272: Subject 118/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 16276: Subject 119/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/16272/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 16312: Subject 120/183\n",
      "\n",
      "Preparing postprocessing dirs 16318: Subject 121/183\n",
      "\n",
      "Preparing postprocessing dirs 16320: Subject 122/183\n",
      "\n",
      "Preparing postprocessing dirs 16343: Subject 123/183\n",
      "\n",
      "Preparing postprocessing dirs 16360: Subject 124/183\n",
      "\n",
      "Preparing postprocessing dirs 16388: Subject 125/183\n",
      "\n",
      "Preparing postprocessing dirs 16399: Subject 126/183\n",
      "\n",
      "Preparing postprocessing dirs 16513: Subject 127/183\n",
      "\n",
      "Preparing postprocessing dirs 16522: Subject 128/183\n",
      "\n",
      "Preparing postprocessing dirs 16545: Subject 129/183\n",
      "\n",
      "Preparing postprocessing dirs 16548: Subject 130/183\n",
      "\n",
      "Preparing postprocessing dirs 16551: Subject 131/183\n",
      "\n",
      "Preparing postprocessing dirs 16552: Subject 132/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 16617: Subject 133/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/16552/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 16636: Subject 134/183\n",
      "\n",
      "Preparing postprocessing dirs 16637: Subject 135/183\n",
      "\n",
      "Preparing postprocessing dirs 16638: Subject 136/183\n",
      "\n",
      "Preparing postprocessing dirs 16639: Subject 137/183\n",
      "\n",
      "Preparing postprocessing dirs 16654: Subject 138/183\n",
      "\n",
      "Preparing postprocessing dirs 16655: Subject 139/183\n",
      "\n",
      "Preparing postprocessing dirs 16658: Subject 140/183\n",
      "\n",
      "Preparing postprocessing dirs 16662: Subject 141/183\n",
      "\n",
      "Preparing postprocessing dirs 16666: Subject 142/183\n",
      "\n",
      "Preparing postprocessing dirs 16667: Subject 143/183\n",
      "\n",
      "Preparing postprocessing dirs 16681: Subject 144/183\n",
      "\n",
      "Preparing postprocessing dirs 16686: Subject 145/183\n",
      "\n",
      "Preparing postprocessing dirs 16689: Subject 146/183\n",
      "\n",
      "Preparing postprocessing dirs 16691: Subject 147/183\n",
      "\n",
      "Preparing postprocessing dirs 16716: Subject 148/183\n",
      "\n",
      "Preparing postprocessing dirs 16722: Subject 149/183\n",
      "\n",
      "Preparing postprocessing dirs 16732: Subject 150/183\n",
      "\n",
      "Preparing postprocessing dirs 16750: Subject 151/183\n",
      "\n",
      "Preparing postprocessing dirs 16761: Subject 152/183\n",
      "\n",
      "Preparing postprocessing dirs 16790: Subject 153/183\n",
      "\n",
      "Preparing postprocessing dirs 16881: Subject 154/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 1761: Subject 155/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/16881/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 2858: Subject 156/183\n",
      "\n",
      "Preparing postprocessing dirs 3535: Subject 157/183\n",
      "\n",
      "Preparing postprocessing dirs 3974: Subject 158/183\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "Some file missing\n",
      "\n",
      "Preparing postprocessing dirs 4334: Subject 159/183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: no se puede borrar '/home/jsilva/Data/IBIS_DATA/Reorder_All/3974/dti/t1_*': No existe el archivo o el directorio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing postprocessing dirs 4507: Subject 160/183\n",
      "\n",
      "Preparing postprocessing dirs 5209: Subject 161/183\n",
      "\n",
      "Preparing postprocessing dirs 5212: Subject 162/183\n",
      "\n",
      "Preparing postprocessing dirs 5660: Subject 163/183\n",
      "\n",
      "Preparing postprocessing dirs 5736: Subject 164/183\n",
      "\n",
      "Preparing postprocessing dirs 5746: Subject 165/183\n",
      "\n",
      "Preparing postprocessing dirs 5817: Subject 166/183\n",
      "\n",
      "Preparing postprocessing dirs 6081: Subject 167/183\n",
      "\n",
      "Preparing postprocessing dirs 6147: Subject 168/183\n",
      "\n",
      "Preparing postprocessing dirs 6148: Subject 169/183\n",
      "\n",
      "Preparing postprocessing dirs 6257: Subject 170/183\n",
      "\n",
      "Preparing postprocessing dirs 6323: Subject 171/183\n",
      "\n",
      "Preparing postprocessing dirs 6406: Subject 172/183\n",
      "\n",
      "Preparing postprocessing dirs 6830: Subject 173/183\n",
      "\n",
      "Preparing postprocessing dirs 6895: Subject 174/183\n",
      "\n",
      "Preparing postprocessing dirs 6903: Subject 175/183\n",
      "\n",
      "Preparing postprocessing dirs 6968: Subject 176/183\n",
      "\n",
      "Preparing postprocessing dirs 8061: Subject 177/183\n",
      "\n",
      "Preparing postprocessing dirs 8079: Subject 178/183\n",
      "\n",
      "Preparing postprocessing dirs 9037: Subject 179/183\n",
      "\n",
      "Preparing postprocessing dirs 9071: Subject 180/183\n",
      "\n",
      "Preparing postprocessing dirs 9114: Subject 181/183\n",
      "\n",
      "Preparing postprocessing dirs 9314: Subject 182/183\n"
     ]
    }
   ],
   "source": [
    "list_dirs = os.listdir(dir_patients)\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "for i in list_dirs:\n",
    "\n",
    "    dir_subj = join(dir_patients,i)\n",
    "    dir_dti = join(dir_subj,'dti')\n",
    "    dir_t1 = join(dir_subj,'cat12','mri')\n",
    "    \n",
    "    \n",
    "    print('\\nPreparing postprocessing dirs %s: Subject %s/%s' %  (i, list_dirs.index(i), len(list_dirs)))\n",
    "\n",
    "    results_dipy = ['dti_md.nii.gz', 'dti_fa.nii.gz']\n",
    "    results_pasternak = ['fw_FW.nii.gz','fw_NoNeg_MD.nii.gz', 'fw_NoNeg_FA.nii.gz', \n",
    "                         'fw_FWE.nii.gz', 'fw_FWE_MD.nii.gz', 'fw_FWE_FA.nii.gz']\n",
    "\n",
    "    for i in results_dipy:\n",
    "        \n",
    "        result = join(dir_dti,i)\n",
    "        warp = join(dir_t1,'t10GenericAffine.mat')\n",
    "        t1_inverted = join(dir_t1,'t1_inverted.nii.gz')\n",
    "        out_ants = join(dir_dti,'t1_%s' % i)\n",
    "\n",
    "        if exists(result):\n",
    "\n",
    "            command='antsApplyTransforms -d 3 -i %s -r %s -o %s -t [%s,1]' % (result, t1_inverted, out_ants, warp)\n",
    "            os.system(command)\n",
    "    \n",
    "            with gzip.open(out_ants, 'rb') as f_in:\n",
    "                with open(out_ants[0:-3], 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "                    \n",
    "            os.remove(out_ants)\n",
    "        \n",
    "        else:\n",
    "            print('Some file missing')\n",
    "\n",
    "    img_to_deform = []\n",
    "    \n",
    "    for i in results_dipy:\n",
    "        \n",
    "        out_ants = 't1_%s' % i[0:-3]\n",
    "        in_docker = join('/dti_data',out_ants)\n",
    "        \n",
    "        if exists(join(dir_dti,out_ants)):\n",
    "            img_to_deform.append(in_docker)\n",
    "\n",
    "    if img_to_deform:\n",
    "\n",
    "        def_matrix = join('/mri_data', 'y_t1.nii')\n",
    "    \n",
    "        mfile_name = join(dir_dti, 'deformations.m')\n",
    "    \n",
    "        design_type_comp = \"matlabbatch{1}.spm.util.defs.comp{1}.\"\n",
    "        design_type_out = \"matlabbatch{1}.spm.util.defs.out{1}.\"\n",
    "    \n",
    "        new_spm = open(mfile_name, \"w\")\n",
    "    \n",
    "        new_spm.write(\n",
    "                design_type_comp + \"def = {'\" + '/mri_data/y_t1.nii' + \"'};\\n\" +\n",
    "                design_type_out + \"pull.fnames = {\" + \"\\n\")\n",
    "    \n",
    "        for image in img_to_deform:\n",
    "            new_spm.write(\"'\" + image + \"'\\n\")\n",
    "        new_spm.write(\"};\\n\")\n",
    "    \n",
    "        new_spm.write(\n",
    "            design_type_out + \"pull.savedir.savesrc = 1;\\n\" +\n",
    "            design_type_out + \"pull.interp =\" + str(4) + \";\\n\" +\n",
    "            design_type_out + \"pull.mask = 0;\\n\" +\n",
    "            design_type_out + \"pull.fwhm = [0 0 0];\\n\" +\n",
    "            design_type_out + \"pull.prefix ='\" + 'w' + \"';\\n\"\n",
    "            )\n",
    "    \n",
    "        new_spm.close()\n",
    "    \n",
    "        client.containers.run(image=\"jhuguetn/cat12\", auto_remove=True, tty=True, stdin_open=True,\n",
    "                                volumes={dir_dti: {\"bind\": \"/dti_data\", \"mode\": \"rw\"},\n",
    "                                        dir_t1: {\"bind\": \"/mri_data\", \"mode\": \"rw\"}},\n",
    "                                command=\"-b /dti_data/deformations.m\")\n",
    "\n",
    "\n",
    "    for i in results_pasternak:\n",
    "        \n",
    "        result = join(dir_dti,'Pasternak',i)\n",
    "        warp = join(dir_t1,'t10GenericAffine.mat')\n",
    "        t1_inverted = join(dir_t1,'t1_inverted.nii.gz')\n",
    "        out_ants = join(dir_dti,'t1_%s' % i)\n",
    "\n",
    "        if exists(result):\n",
    "\n",
    "            command='antsApplyTransforms -d 3 -i %s -r %s -o %s -t [%s,1]' % (result, t1_inverted, out_ants, warp)\n",
    "            os.system(command)\n",
    "    \n",
    "            with gzip.open(out_ants, 'rb') as f_in:\n",
    "                with open(out_ants[0:-3], 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "                    \n",
    "            os.remove(out_ants)\n",
    "        \n",
    "        else:\n",
    "            print('Some file missing')\n",
    "\n",
    "    img_to_deform = []\n",
    "    \n",
    "    for i in results_pasternak:\n",
    "        \n",
    "        out_ants = 't1_%s' % i[0:-3]\n",
    "        in_docker = join('/dti_data',out_ants)\n",
    "        \n",
    "        if exists(join(dir_dti,out_ants)):\n",
    "            img_to_deform.append(in_docker)\n",
    "\n",
    "    if img_to_deform:\n",
    "\n",
    "        def_matrix = join('/mri_data', 'y_t1.nii')\n",
    "    \n",
    "        mfile_name = join(dir_dti, 'deformations.m')\n",
    "    \n",
    "        design_type_comp = \"matlabbatch{1}.spm.util.defs.comp{1}.\"\n",
    "        design_type_out = \"matlabbatch{1}.spm.util.defs.out{1}.\"\n",
    "    \n",
    "        new_spm = open(mfile_name, \"w\")\n",
    "    \n",
    "        new_spm.write(\n",
    "                design_type_comp + \"def = {'\" + '/mri_data/y_t1.nii' + \"'};\\n\" +\n",
    "                design_type_out + \"pull.fnames = {\" + \"\\n\")\n",
    "    \n",
    "        for image in img_to_deform:\n",
    "            new_spm.write(\"'\" + image + \"'\\n\")\n",
    "        new_spm.write(\"};\\n\")\n",
    "    \n",
    "        new_spm.write(\n",
    "            design_type_out + \"pull.savedir.savesrc = 1;\\n\" +\n",
    "            design_type_out + \"pull.interp =\" + str(4) + \";\\n\" +\n",
    "            design_type_out + \"pull.mask = 0;\\n\" +\n",
    "            design_type_out + \"pull.fwhm = [0 0 0];\\n\" +\n",
    "            design_type_out + \"pull.prefix ='\" + 'w' + \"';\\n\"\n",
    "            )\n",
    "    \n",
    "        new_spm.close()\n",
    "    \n",
    "        client.containers.run(image=\"jhuguetn/cat12\", auto_remove=True, tty=True, stdin_open=True,\n",
    "                                volumes={dir_dti: {\"bind\": \"/dti_data\", \"mode\": \"rw\"},\n",
    "                                        dir_t1: {\"bind\": \"/mri_data\", \"mode\": \"rw\"}},\n",
    "                                command=\"-b /dti_data/deformations.m\")\n",
    "\n",
    "    os.system('rm %s/t1_*' % dir_dti)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
